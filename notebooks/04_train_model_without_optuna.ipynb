{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "quIhilm65orD",
    "outputId": "daf0111b-5a1f-4c55-95e2-d46b5143ee37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.13/site-packages (3.1.2)\n",
      "Requirement already satisfied: lightgbm in /opt/anaconda3/lib/python3.13/site-packages (4.6.0)\n",
      "Requirement already satisfied: mlflow<3 in /opt/anaconda3/lib/python3.13/site-packages (2.22.4)\n",
      "Requirement already satisfied: mlflow-skinny==2.22.4 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (2.22.4)\n",
      "Requirement already satisfied: Flask<4 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (3.1.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (3.1.6)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (1.16.4)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (23.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (3.8)\n",
      "Requirement already satisfied: matplotlib<4 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (3.10.0)\n",
      "Requirement already satisfied: numpy<3 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (2.1.3)\n",
      "Requirement already satisfied: pandas!=2.3.0,<3 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (19.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (1.6.1)\n",
      "Requirement already satisfied: scipy<2 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (1.15.3)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow<3) (2.0.39)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle<4 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (3.0.0)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.74.0)\n",
      "Requirement already satisfied: fastapi<1 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.124.4)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (3.1.43)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (1.39.1)\n",
      "Requirement already satisfied: packaging<25 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (24.2)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (5.29.5)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (2.10.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (6.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.5.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (4.15.0)\n",
      "Requirement already satisfied: uvicorn<1 in /opt/anaconda3/lib/python3.13/site-packages (from mlflow-skinny==2.22.4->mlflow<3) (0.38.0)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.13/site-packages (from alembic!=1.10.0,<2->mlflow<3) (1.2.3)\n",
      "Requirement already satisfied: google-auth~=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (2.43.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/anaconda3/lib/python3.13/site-packages (from docker<8,>=4.0.0->mlflow<3) (2.3.0)\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /opt/anaconda3/lib/python3.13/site-packages (from fastapi<1->mlflow-skinny==2.22.4->mlflow<3) (0.50.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /opt/anaconda3/lib/python3.13/site-packages (from fastapi<1->mlflow-skinny==2.22.4->mlflow<3) (0.0.4)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /opt/anaconda3/lib/python3.13/site-packages (from Flask<4->mlflow<3) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /opt/anaconda3/lib/python3.13/site-packages (from Flask<4->mlflow<3) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in /opt/anaconda3/lib/python3.13/site-packages (from Flask<4->mlflow<3) (1.9.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.4->mlflow<3) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.4->mlflow<3) (4.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.13/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (4.9.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /opt/anaconda3/lib/python3.13/site-packages (from graphene<4->mlflow<3) (3.2.7)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /opt/anaconda3/lib/python3.13/site-packages (from graphene<4->mlflow<3) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from graphene<4->mlflow<3) (2.9.0.post0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/anaconda3/lib/python3.13/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.4->mlflow<3) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from Jinja2<4,>=2.11->mlflow<3) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib<4->mlflow<3) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib<4->mlflow<3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib<4->mlflow<3) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib<4->mlflow<3) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib<4->mlflow<3) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib<4->mlflow<3) (3.2.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /opt/anaconda3/lib/python3.13/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.4->mlflow<3) (0.60b1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas!=2.3.0,<3->mlflow<3) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas!=2.3.0,<3->mlflow<3) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.4->mlflow<3) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.4->mlflow<3) (2.27.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow<3) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.4->mlflow<3) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.4->mlflow<3) (0.4.8)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn<2->mlflow<3) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn<2->mlflow<3) (3.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /opt/anaconda3/lib/python3.13/site-packages (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.4->mlflow<3) (4.7.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.13/site-packages (from anyio<5,>=3.6.2->starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.4->mlflow<3) (1.3.0)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/anaconda3/lib/python3.13/site-packages (from uvicorn<1->mlflow-skinny==2.22.4->mlflow<3) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost lightgbm \"mlflow<3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTqNkkbR33iG",
    "outputId": "463058a0-4a86-4aa1-b191-dd24eb27442d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MLflow experiment set to 'Churn_Prediction_Baseline'\n",
      "‚úì STEP 1: Preprocessing pipeline created.\n",
      "‚úÖ Data loaded successfully!\n",
      "   Training set (X_train): (8000, 12)\n",
      "   Test set (X_test):  (2000, 12)\n",
      "‚úì STEP 3: 4 baseline model pipelines defined.\n",
      "‚úì STEP 4: MLflow configured. Experiment name: 'Churn_Prediction_Multi_Models'\n",
      "\n",
      "================================================================================\n",
      "üöÄ STEP 5: Training & Logging 4 Baseline Models (Without PCA)\n",
      "================================================================================\n",
      "\n",
      "üîπ Training model: ridge\n",
      "   CV F1 Score: 0.2407 (+/- 0.0111)\n",
      "   Test F1 Score: 0.2152\n",
      "   Confusion Matrix: TP=58, TN=1519, FP=74, FN=349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'ridge_pipeline_no_pca' already exists. Creating a new version of this model...\n",
      "2025/12/18 19:04:15 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ridge_pipeline_no_pca, version 4\n",
      "Created version '4' of model 'ridge_pipeline_no_pca'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run ridge_baseline at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0/runs/8e0206cb309a4a5ab9ee418d69bb2c9c\n",
      "üß™ View experiment at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0\n",
      "\n",
      "üîπ Training model: histgradientboosting\n",
      "   CV F1 Score: 0.5913 (+/- 0.0023)\n",
      "   Test F1 Score: 0.5870\n",
      "   Confusion Matrix: TP=199, TN=1521, FP=72, FN=208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'histgradientboosting_pipeline_no_pca' already exists. Creating a new version of this model...\n",
      "2025/12/18 19:04:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: histgradientboosting_pipeline_no_pca, version 3\n",
      "Created version '3' of model 'histgradientboosting_pipeline_no_pca'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run histgradientboosting_baseline at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0/runs/80db14cfeaa4426b8468dbdb0886cb39\n",
      "üß™ View experiment at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0\n",
      "\n",
      "üîπ Training model: xgboost\n",
      "   CV F1 Score: 0.5804 (+/- 0.0129)\n",
      "   Test F1 Score: 0.5805\n",
      "   Confusion Matrix: TP=191, TN=1533, FP=60, FN=216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'xgboost_pipeline_no_pca' already exists. Creating a new version of this model...\n",
      "2025/12/18 19:05:15 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_pipeline_no_pca, version 3\n",
      "Created version '3' of model 'xgboost_pipeline_no_pca'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run xgboost_baseline at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0/runs/87b53d4d3d2f43169ed7f6282784957e\n",
      "üß™ View experiment at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0\n",
      "\n",
      "üîπ Training model: lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CV F1 Score: 0.5906 (+/- 0.0111)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Test F1 Score: 0.5855\n",
      "   Confusion Matrix: TP=190, TN=1541, FP=52, FN=217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "Registered model 'lightgbm_pipeline_no_pca' already exists. Creating a new version of this model...\n",
      "2025/12/18 19:05:41 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: lightgbm_pipeline_no_pca, version 3\n",
      "Created version '3' of model 'lightgbm_pipeline_no_pca'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run lightgbm_baseline at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0/runs/9ec47f0fdd0440eda8a0ca55f576f698\n",
      "üß™ View experiment at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0\n",
      "\n",
      "‚úì STEP 5: All 4 baseline models trained and logged successfully.\n",
      "\n",
      "================================================================================\n",
      "üöÄ STEP 7: Training PCA-Augmented Models (Target: F1 Score)\n",
      "================================================================================\n",
      "\n",
      "üîπ Training PCA model: ridge\n",
      "   CV F1 Score: 0.2211 (+/- 0.0067)\n",
      "   Test F1 Score: 0.2058\n",
      "   Confusion Matrix: TP=50, TN=1564, FP=29, FN=357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'ridge_pipeline_with_pca' already exists. Creating a new version of this model...\n",
      "2025/12/18 19:06:12 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: ridge_pipeline_with_pca, version 3\n",
      "Created version '3' of model 'ridge_pipeline_with_pca'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run ridge_with_pca at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0/runs/8c2ed25b7dd94b36bd959e8d522a997d\n",
      "üß™ View experiment at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0\n",
      "\n",
      "üîπ Training PCA model: histgradientboosting\n",
      "   CV F1 Score: 0.5096 (+/- 0.0139)\n",
      "   Test F1 Score: 0.5526\n",
      "   Confusion Matrix: TP=176, TN=1539, FP=54, FN=231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'histgradientboosting_pipeline_with_pca' already exists. Creating a new version of this model...\n",
      "2025/12/18 19:07:07 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: histgradientboosting_pipeline_with_pca, version 3\n",
      "Created version '3' of model 'histgradientboosting_pipeline_with_pca'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run histgradientboosting_with_pca at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0/runs/49bfe128eaaa4d638f7a3918d15ef113\n",
      "üß™ View experiment at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0\n",
      "\n",
      "üîπ Training PCA model: xgboost\n",
      "   CV F1 Score: 0.5064 (+/- 0.0141)\n",
      "   Test F1 Score: 0.5483\n",
      "   Confusion Matrix: TP=176, TN=1534, FP=59, FN=231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "Registered model 'xgboost_pipeline_with_pca' already exists. Creating a new version of this model...\n",
      "2025/12/18 19:07:41 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: xgboost_pipeline_with_pca, version 3\n",
      "Created version '3' of model 'xgboost_pipeline_with_pca'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run xgboost_with_pca at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0/runs/46bd4fb19ea44e168731f3bd19786eb4\n",
      "üß™ View experiment at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0\n",
      "\n",
      "üîπ Training PCA model: lightgbm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CV F1 Score: 0.5286 (+/- 0.0210)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Test F1 Score: 0.5597\n",
      "   Confusion Matrix: TP=178, TN=1542, FP=51, FN=229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "Registered model 'lightgbm_pipeline_with_pca' already exists. Creating a new version of this model...\n",
      "2025/12/18 19:08:13 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: lightgbm_pipeline_with_pca, version 3\n",
      "Created version '3' of model 'lightgbm_pipeline_with_pca'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run lightgbm_with_pca at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0/runs/60fed03c82d7479789e56d65ed2a0a61\n",
      "üß™ View experiment at: https://dagshub.com/williamzhang430/Churning_Model.mlflow/#/experiments/0\n",
      "\n",
      "‚úì STEP 7: All 4 PCA models trained and logged.\n",
      "\n",
      "================================================================================\n",
      "üèÜ GLOBAL BEST MODEL (ACROSS 8 CANDIDATES)\n",
      "================================================================================\n",
      "Global best model key : histgradientboosting\n",
      "Global best CV F1     : 0.5913\n",
      "Global best Test F1   : 0.5870\n",
      "Uses PCA              : False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Saving GLOBAL best model...\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Model saved to models/global_best_model.pkl\n",
      "\n",
      "Done:\n",
      "- GLOBAL best model key : histgradientboosting\n",
      "- GLOBAL best CV F1     : 0.5913\n",
      "- GLOBAL best Test F1   : 0.5870\n",
      "\n",
      "‚è±Ô∏è Elapsed Time: 4 minutes and 16.70 seconds\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FULL PIPELINE:\n",
    "# - Build preprocessing\n",
    "# - Stratified train/test split\n",
    "# - Train & log 4 models WITHOUT PCA (Ridge, HGB, XGBoost, LightGBM)\n",
    "# - Train & log 4 models WITH PCA (preprocessing + PCA(0.95) + model)\n",
    "# - Pick GLOBAL best among 8 models by Test MAE\n",
    "# - Save, load, and compare the global best model\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "project_root = os.path.abspath(\"..\")\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import shared components\n",
    "from churning_pipeline import (\n",
    "    build_preprocessing,\n",
    "    make_estimator_for_name,\n",
    ")\n",
    "\n",
    "start_time = time.monotonic()\n",
    "\n",
    "# Set MLflow experiment name\n",
    "mlflow.set_experiment(\"Churn_Prediction_Baseline\")\n",
    "print(\"‚úÖ MLflow experiment set to 'Churn_Prediction_Baseline'\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: Build Full ML Preprocessing Pipeline\n",
    "# =============================================================================\n",
    "\n",
    "preprocessing = build_preprocessing()\n",
    "print(\"‚úì STEP 1: Preprocessing pipeline created.\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: Load Stratified Train and Test Sets\n",
    "# =============================================================================\n",
    "\n",
    "# Load Data\n",
    "data_dir = \"../data\" if os.path.exists(\"../data\") else \"data\"\n",
    "train_path = os.path.join(data_dir, \"strat_train_set.csv\")\n",
    "test_path = os.path.join(data_dir, \"strat_test_set.csv\")\n",
    "\n",
    "# Read csv files\n",
    "churning_train = pd.read_csv(train_path)\n",
    "churning_test = pd.read_csv(test_path)\n",
    "\n",
    "# Separate features and target variable\n",
    "# Target variable: \"exited\"\n",
    "X_train = churning_train.drop(\"exited\", axis=1)\n",
    "y_train = churning_train[\"exited\"].copy()\n",
    "\n",
    "X_test = churning_test.drop(\"exited\", axis=1)\n",
    "y_test = churning_test[\"exited\"].copy()\n",
    "\n",
    "X_train.columns = X_train.columns.str.lower()\n",
    "X_test.columns = X_test.columns.str.lower()\n",
    "\n",
    "print(f\"‚úÖ Data loaded successfully!\")\n",
    "print(f\"   Training set (X_train): {X_train.shape}\")\n",
    "print(f\"   Test set (X_test):  {X_test.shape}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: Define 4 Model Pipelines (WITHOUT PCA)\n",
    "# =============================================================================\n",
    "\n",
    "models = {}\n",
    "for name in [\"ridge\", \"histgradientboosting\", \"xgboost\", \"lightgbm\"]:\n",
    "    est = make_estimator_for_name(name)\n",
    "    models[name] = make_pipeline(preprocessing, est)\n",
    "\n",
    "print(\"‚úì STEP 3: 4 baseline model pipelines defined.\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: Configure MLflow (e.g., Dagshub) via .env\n",
    "# =============================================================================\n",
    "\n",
    "# 1. Load .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "MLFLOW_TRACKING_USERNAME = os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n",
    "MLFLOW_TRACKING_PASSWORD = os.getenv(\"MLFLOW_TRACKING_PASSWORD\")\n",
    "\n",
    "# 2. Check if MLFLOW_TRACKING_URI exists\n",
    "if not MLFLOW_TRACKING_URI:\n",
    "    print(\"‚ö†Ô∏è WARNING: MLFLOW_TRACKING_URI is not set. Using local MLflow setup.\")\n",
    "else:\n",
    "    # Set environment variables for authentication\n",
    "    if MLFLOW_TRACKING_USERNAME:\n",
    "        os.environ[\"MLFLOW_TRACKING_USERNAME\"] = MLFLOW_TRACKING_USERNAME\n",
    "    if MLFLOW_TRACKING_PASSWORD:\n",
    "        os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = MLFLOW_TRACKING_PASSWORD\n",
    "\n",
    "    # 3. Connect to Dagshub MLflow Tracking Server\n",
    "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "    experiment_name = \"Churn_Prediction_Multi_Models\"\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    print(f\"‚úì STEP 4: MLflow configured. Experiment name: '{experiment_name}'\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 5: Train, Evaluate, and Log 4 Baseline Models (NO PCA)\n",
    "# =============================================================================\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"üöÄ STEP 5: Training & Logging 4 Baseline Models (Without PCA)\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "for name, pipeline in models.items():\n",
    "    print(f\"\\nüîπ Training model: {name}\")\n",
    "\n",
    "    # --- 1. Cross Validation (CV) ---\n",
    "    cv_scores = cross_val_score(\n",
    "        pipeline, X_train, y_train,\n",
    "        cv=3, scoring=\"f1\", n_jobs=-1\n",
    "    )\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "    \n",
    "    print(f\"   CV F1 Score: {cv_mean:.4f} (+/- {cv_std:.4f})\")\n",
    "\n",
    "    # --- 2. Fit on Full Training Set ---\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # --- 3. Evaluate on Test Set ---\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    print(f\"   Test F1 Score: {test_f1:.4f}\")\n",
    "    print(f\"   Confusion Matrix: TP={tp}, TN={tn}, FP={fp}, FN={fn}\")\n",
    "\n",
    "    results[name] = {\n",
    "        \"pipeline\": pipeline, \n",
    "        \"test_f1\": test_f1, \n",
    "        \"cv_f1_mean\": cv_mean\n",
    "    }\n",
    "\n",
    "    # --- 4. Log to MLflow ---\n",
    "    with mlflow.start_run(run_name=f\"{name}_baseline\"):\n",
    "        # Log basic parameters\n",
    "        mlflow.log_param(\"model_family\", name)\n",
    "        mlflow.log_param(\"uses_pca\", False)\n",
    "\n",
    "        # Log model parameters\n",
    "        est_step_name = list(pipeline.named_steps.keys())[-1]\n",
    "        est = pipeline.named_steps[est_step_name]\n",
    "        est_params = {f\"{est_step_name}__{k}\": v for k, v in est.get_params().items()}\n",
    "        mlflow.log_params(est_params)\n",
    "\n",
    "        # Log core metrics (Metric)\n",
    "        mlflow.log_metric(\"cv_f1_mean\", cv_mean)\n",
    "        mlflow.log_metric(\"cv_f1_std\", cv_std)\n",
    "        mlflow.log_metric(\"test_f1\", test_f1)\n",
    "        mlflow.log_metric(\"test_accuracy\", test_acc)\n",
    "        \n",
    "        # Log confusion matrix components\n",
    "        mlflow.log_metric(\"test_tp\", tp)\n",
    "        mlflow.log_metric(\"test_tn\", tn)\n",
    "        mlflow.log_metric(\"test_fp\", fp)\n",
    "        mlflow.log_metric(\"test_fn\", fn)\n",
    "\n",
    "        # Log model\n",
    "        signature = infer_signature(X_train, pipeline.predict(X_train))\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=pipeline,\n",
    "            artifact_path=\"churn_model\", \n",
    "            signature=signature,\n",
    "            input_example=X_train.iloc[:5],\n",
    "            registered_model_name=f\"{name}_pipeline_no_pca\",\n",
    "        )\n",
    "\n",
    "print(\"\\n‚úì STEP 5: All 4 baseline models trained and logged successfully.\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 7: Train, Evaluate, and Log PCA Versions of ALL 4 Models\n",
    "# =============================================================================\n",
    "\n",
    "pca_results = {}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"üöÄ STEP 7: Training PCA-Augmented Models (Target: F1 Score)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name in models.keys():\n",
    "    print(f\"\\nüîπ Training PCA model: {name}\")\n",
    "\n",
    "    # 1. Get untrained estimator\n",
    "    est = make_estimator_for_name(name)\n",
    "\n",
    "    # 2. Build pipeline with PCA\n",
    "    pca_pipeline = make_pipeline(\n",
    "        preprocessing,\n",
    "        PCA(n_components=0.95),\n",
    "        est,\n",
    "    )\n",
    "\n",
    "    # 3. Cross Validation (CV)\n",
    "    cv_scores_pca = cross_val_score(\n",
    "        pca_pipeline, X_train, y_train,\n",
    "        cv=3, scoring=\"f1\", n_jobs=-1\n",
    "    )\n",
    "    cv_mean_pca = cv_scores_pca.mean()\n",
    "    cv_std_pca = cv_scores_pca.std()\n",
    "    \n",
    "    print(f\"   CV F1 Score: {cv_mean_pca:.4f} (+/- {cv_std_pca:.4f})\")\n",
    "\n",
    "    # 4. Fit on Full Training Set\n",
    "    pca_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # 5. Evaluate on Test Set\n",
    "    y_pred_pca = pca_pipeline.predict(X_test)\n",
    "    \n",
    "    test_f1_pca = f1_score(y_test, y_pred_pca)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_pca).ravel()\n",
    "\n",
    "    model_key = f\"{name}_with_pca\"\n",
    "    pca_results[model_key] = {\n",
    "        \"pipeline\": pca_pipeline,\n",
    "        \"test_f1\": test_f1_pca,\n",
    "        \"cv_f1_mean\": cv_mean_pca,\n",
    "    }\n",
    "\n",
    "    print(f\"   Test F1 Score: {test_f1_pca:.4f}\")\n",
    "    print(f\"   Confusion Matrix: TP={tp}, TN={tn}, FP={fp}, FN={fn}\")\n",
    "\n",
    "    # 6. Log to MLflow\n",
    "    with mlflow.start_run(run_name=model_key):\n",
    "        mlflow.log_param(\"model_family\", name)\n",
    "        mlflow.log_param(\"uses_pca\", True)\n",
    "\n",
    "        # Log basic parameters\n",
    "        est_step_name = list(pca_pipeline.named_steps.keys())[-1]\n",
    "        est_step = pca_pipeline.named_steps[est_step_name]\n",
    "        est_params = {f\"{est_step_name}__{k}\": v for k, v in est_step.get_params().items()}\n",
    "        mlflow.log_params(est_params)\n",
    "\n",
    "        # Log PCA parameters\n",
    "        pca_step = pca_pipeline.named_steps[\"pca\"]\n",
    "        mlflow.log_param(\"pca__n_components\", pca_step.n_components)\n",
    "\n",
    "        # Log core metrics (Metric)\n",
    "        mlflow.log_metric(\"cv_f1_mean\", cv_mean_pca)\n",
    "        mlflow.log_metric(\"cv_f1_std\", cv_std_pca)\n",
    "        mlflow.log_metric(\"test_f1\", test_f1_pca)\n",
    "        \n",
    "        # Log confusion matrix components\n",
    "        mlflow.log_metric(\"test_tp\", tp)\n",
    "        mlflow.log_metric(\"test_tn\", tn)\n",
    "        mlflow.log_metric(\"test_fp\", fp)\n",
    "        mlflow.log_metric(\"test_fn\", fn)\n",
    "\n",
    "        # Log model\n",
    "        signature_pca = infer_signature(X_train, pca_pipeline.predict(X_train))\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=pca_pipeline,\n",
    "            artifact_path=\"churn_model_pca\",\n",
    "            signature=signature_pca,\n",
    "            input_example=X_train.iloc[:5],\n",
    "            registered_model_name=f\"{name}_pipeline_with_pca\",\n",
    "        )\n",
    "\n",
    "print(\"\\n‚úì STEP 7: All 4 PCA models trained and logged.\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 8: Choose GLOBAL Best Model (with or without PCA)\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# 1. Combine all results\n",
    "all_results = {}\n",
    "all_results.update(results)      # 4 models without PCA\n",
    "all_results.update(pca_results)  # 4 models with PCA\n",
    "\n",
    "# 2. Choose the global best model based on Test F1 Score\n",
    "global_best_name = max(all_results, key=lambda k: all_results[k][\"test_f1\"])\n",
    "\n",
    "# 3. Extract the best model's details\n",
    "global_best_f1 = all_results[global_best_name][\"test_f1\"]\n",
    "global_best_cv_f1 = all_results[global_best_name][\"cv_f1_mean\"]\n",
    "global_best_pipeline = all_results[global_best_name][\"pipeline\"]\n",
    "\n",
    "# 4. Check if PCA was used\n",
    "uses_pca = \"with_pca\" in global_best_name\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèÜ GLOBAL BEST MODEL (ACROSS 8 CANDIDATES)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Global best model key : {global_best_name}\")\n",
    "print(f\"Global best CV F1     : {global_best_cv_f1:.4f}\")\n",
    "print(f\"Global best Test F1   : {global_best_f1:.4f}\")\n",
    "print(f\"Uses PCA              : {uses_pca}\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 9: Save, Load, and Compare the GLOBAL Best Model\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# 1. Make sure models/ directory exists\n",
    "models_dir = \"models\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    print(f\"üìÅ Created directory: {models_dir}\")\n",
    "\n",
    "# 2. Define save function\n",
    "def save_model(model, filename):\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"‚úì Model saved to {filename}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Saving GLOBAL best model...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# 3. Save the GLOBAL best model\n",
    "save_path = os.path.join(models_dir, \"global_best_model.pkl\")\n",
    "save_model(global_best_pipeline, filename=save_path)\n",
    "\n",
    "# 4. Print final summary (modified to F1 metrics)\n",
    "print(\"\\nDone:\")\n",
    "print(f\"- GLOBAL best model key : {global_best_name}\")\n",
    "print(f\"- GLOBAL best CV F1     : {global_best_cv_f1:.4f}\")\n",
    "print(f\"- GLOBAL best Test F1   : {global_best_f1:.4f}\")\n",
    "\n",
    "# 5. Measure total execution time\n",
    "end_time = time.monotonic()\n",
    "elapsed_time = end_time - start_time\n",
    "minutes = int(elapsed_time // 60)\n",
    "seconds = elapsed_time % 60\n",
    "print(f\"\\n‚è±Ô∏è Elapsed Time: {minutes} minutes and {seconds:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
