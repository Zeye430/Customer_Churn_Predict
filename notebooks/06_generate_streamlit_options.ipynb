{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5Xua_0H-pn8",
    "outputId": "3ed53e68-00ab-45e5-e294-47896aec6e63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading data from: ../data/strat_train_set.csv\n",
      "âœ… Data loaded. Shape: (8000, 13)\n",
      "\n",
      "================================================================================\n",
      "ANALYZING CHURN DATA FOR STREAMLIT APP\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "NUMERICAL FEATURES\n",
      "--------------------------------------------------------------------------------\n",
      "Feature                   Min             Max             Mean            Median         \n",
      "--------------------------------------------------------------------------------\n",
      "credit_score              350.00          850.00          650.75          652.00         \n",
      "age                       18.00           92.00           38.95           37.00          \n",
      "tenure                    0.00            10.00           5.02            5.00           \n",
      "balance                   0.00            238387.56       76381.21        97055.15       \n",
      "num_of_products           1.00            4.00            1.53            1.00           \n",
      "estimated_salary          11.58           199992.48       99730.81        99446.94       \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CATEGORICAL FEATURES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "geography:\n",
      "  Unique values: ['France', 'Germany', 'Spain']\n",
      "\n",
      "gender:\n",
      "  Unique values: ['Male', 'Female']\n",
      "\n",
      "has_cr_card:\n",
      "  Unique values: [1, 0]\n",
      "\n",
      "is_active_member:\n",
      "  Unique values: [0, 1]\n",
      "\n",
      "================================================================================\n",
      "âœ“ Data schema saved to ../data/data_schema.json\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ANALYZE CHURNING DATA FOR STREAMLIT APP\n",
    "# Find min/max/median for numerical features and unique values for categorical features\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 1. Setting up: Load the data\n",
    "data_path = \"data/strat_train_set.csv\"\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    data_path = \"../data/strat_train_set.csv\"\n",
    "\n",
    "print(f\"ðŸ“‚ Loading data from: {data_path}\")\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "print(f\"âœ… Data loaded. Shape: {df.shape}\")\n",
    "\n",
    "# 2. Define feature lists\n",
    "numerical_features = [\n",
    "    'credit_score',\n",
    "    'age',\n",
    "    'tenure',\n",
    "    'balance',\n",
    "    'num_of_products',\n",
    "    'estimated_salary'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'geography',\n",
    "    'gender',\n",
    "    'has_cr_card',      \n",
    "    'is_active_member'  \n",
    "]\n",
    "\n",
    "# 3. Create data schema dictionary\n",
    "data_schema = {\n",
    "    \"numerical\": {},\n",
    "    \"categorical\": {}\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANALYZING CHURN DATA FOR STREAMLIT APP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 4. Analyze numerical features\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"NUMERICAL FEATURES\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Feature':<25} {'Min':<15} {'Max':<15} {'Mean':<15} {'Median':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for feature in numerical_features:\n",
    "    min_val = float(df[feature].min())\n",
    "    max_val = float(df[feature].max())\n",
    "    mean_val = float(df[feature].mean())\n",
    "    median_val = float(df[feature].median())\n",
    "\n",
    "    data_schema[\"numerical\"][feature] = {\n",
    "        \"min\": min_val,\n",
    "        \"max\": max_val,\n",
    "        \"mean\": mean_val,\n",
    "        \"median\": median_val\n",
    "    }\n",
    "\n",
    "    print(f\"{feature:<25} {min_val:<15.2f} {max_val:<15.2f} {mean_val:<15.2f} {median_val:<15.2f}\")\n",
    "\n",
    "# 5. Analyze categorical features\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"CATEGORICAL FEATURES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for feature in categorical_features:\n",
    "    unique_values = df[feature].unique().tolist()\n",
    "    if hasattr(unique_values[0], 'item'): \n",
    "         unique_values = [int(x) for x in unique_values]\n",
    "         \n",
    "    value_counts = df[feature].value_counts().to_dict()\n",
    "    \n",
    "    data_schema[\"categorical\"][feature] = {\n",
    "        \"unique_values\": unique_values,\n",
    "        \"value_counts\": {str(k): int(v) for k, v in value_counts.items()} \n",
    "    }\n",
    "\n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(f\"  Unique values: {unique_values}\")\n",
    "\n",
    "# 6. Save the data schema to a JSON file\n",
    "output_dir = os.path.join(\"..\", \"data\")\n",
    "\n",
    "output_file = os.path.join(output_dir, \"data_schema.json\")\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(data_schema, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"âœ“ Data schema saved to {output_file}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
